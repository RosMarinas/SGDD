# issue8-Smoke testing
## 描述
在进行大规模修改或添加新功能后，进行全面的冒烟测试，确保系统的基本功能正常运行，没有引入新的严重错误。重点是确保模型框架没有问题，在严重过拟合下能够正确输出结果。
## 任务
在**tests/**目录下进行冒烟测试，使用BookCorpus数据集的一个很小的子集（例如64条样本），进行反复训练，确保模型能够正常训练和生成文本。在训练后要使用evaluate.py一致的逻辑进行评估，确保生成结果合理且正确，由于是冒烟测试，此时推理输出与训练结果应该一致。
需要验证模型框架的以下内容：
1. 架构正确性：确保模型的各个组件正确连接，前向传播和反向传播没有错误。
2. 训练稳定性：在小数据集上训练时，损失函数应当稳定下降，没有出现NaN或Inf。
3. 推理正确性：在训练后进行推理，确保生成的文本符合预期格式，没有明显错误。
4. 日志记录：确保训练和评估过程中的日志记录正确，能够追踪训练进度和结果。
5. 能够实现diffusion变长输出，模型能够正确生成结束符号与padding符号。