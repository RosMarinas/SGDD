# Phase 1: Whitening Optimization
# Task: Reconstruction with Whitening (BGE-M3 + BookCorpus)
# Dataset: BookCorpus

# Model Config
model:
  encoder_name: "BAAI/bge-m3"
  encoder_freeze: true
  semantic_dim: 1024
  decoder_dim: 256
  # whitening_stats_path: "data/whitening_stats_bge.pt" 

  # VIB Configuration
  kl_weight: 0.1
  kl_anneal_steps: 600

  # Decoder
  num_layers: 2
  num_heads: 4
  ffn_dim: 1024
  max_length: 64
  dropout: 0.1

  num_diffusion_steps: 1000
  noise_schedule: "cosine"

  # Training Optimization
  use_self_conditioning: true
  compute_pad_loss: false
  compute_eos_loss: true

# Training Config
training:
  learning_rate: 0.00015
  weight_decay: 0.01
  batch_size: 32
  num_epochs: 30
  gradient_accumulation_steps: 2
  grad_clip: 1.0

  lr_scheduler: "cosine"
  warmup_steps: 200

  use_fp16: true
  cfg_drop_prob: 0.15

  log_interval: 20
  save_interval: 1000
  eval_interval: 200
  save_epochs: 5

  use_wandb: true
  wandb_project: "sgdd-vib-bge"
  wandb_run_name: "phase1_whitening_bookcorpus"

# Data Config
data:
  dataset: "bookcorpus"
  dataset_path: "data/BookCorpus/final_dataset_1.4B"
  max_token_length: 64
  min_length: 5

  num_workers: 4
  pin_memory: true
  val_split: 0.03

# Inference Config
inference:
  num_inference_steps: 16
  temperature: 1.0
  cfg_scale: 2.0
  sampling_strategy: "confidence"

# System Config
seed: 520
device: "cuda"
checkpoint_dir: "checkpoints/phase1_whitening_bge"
log_dir: "logs/phase1_whitening_bge"
task: "reconstruction"